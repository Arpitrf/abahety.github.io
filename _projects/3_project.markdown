---
layout: page
title: Hand-Gesture Based Human Robot Interaction Using 3D CNN
duration: (July - December 2018)
description: This project aimed to develop a system for hand gesture recognition and implement that on a Nao Robot. Such a system could potentially help people with speech imparity interact with robots.
img: /assets/img/hand_gesture.gif
importance: 3
category: work
github: https://github.com/Arpitrf/Hand-Gesture-Recognition
# report: https://drive.google.com/file/d/1JlGMaFjB9gv7hZZIYtLv02e9lrfrHBer/view?usp=sharing
---

Modeled a novel 3D Convolutional Neural Network and trained it on the 20bn Jester Dataset to recognize various gestures. The trained model was then integrated with Nao robot for real time gesture recognition. Also Tackled the problem of limited computing power of Nao by creating an interactive pipeline between Nao and an external system performing all the computations.

[Report](https://drive.google.com/file/d/1JlGMaFjB9gv7hZZIYtLv02e9lrfrHBer/view?usp=sharing)

